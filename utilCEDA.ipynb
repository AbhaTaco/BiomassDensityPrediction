{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhPcLPPOZvhEgyQbXskaDs"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import ee\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.metrics import mean_squared_error, mean_absolute_error\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","import xgboost as xgb\n","\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.colors as mcolors\n","\n","import seaborn as sns\n","\n","# Utility Functions\n","# ***********************\n","\n","# Input coordinates to make a geometry\n","\n","def makeGeometry(coordinates):\n","\n","  dlat = 0.326\n","  dlong = 0.21568\n","\n","  lat = coordinates[0]\n","  longit = coordinates[1]\n","  latp = lat + dlat\n","  longp = longit + dlong\n","\n","  print(lat, longit, latp, longp)\n","  geometry = ee.Geometry.Rectangle(lat, longit, latp, longp)\n","\n","  return geometry\n","\n","\n","# ***********************\n","# Sentinel\n","# ***********************\n","\n","# Function to apply scale factor to convert\n","# pixel values to reflectances\n","def scaleBands(image):\n","  return image.multiply(0.0001) \\\n","    .copyProperties(image, ['system:time_start'])\n","\n","\n","# Function to mask pixels with low CS+ QA scores.\n","def maskLowQA(image):\n","  qaBand = 'cs'\n","  clearThreshold = 0.5\n","  mask = image.select(qaBand).gte(clearThreshold)\n","  return image.updateMask(mask)\n","\n","\n","# Function to compute spectral indices\n","def addIndices(image):\n","  ndvi = image.normalizedDifference(['B8', 'B4']) \\\n","    .rename('ndvi')\n","\n","  mndwi = image.normalizedDifference(['B3', 'B11']) \\\n","    .rename('mndwi')\n","\n","  ndbi = image.normalizedDifference(['B11', 'B8']) \\\n","    .rename('ndbi')\n","\n","  evi = image.expression(\n","    '2.5 * ((NIR - RED)/(NIR + 6*RED - 7.5*BLUE + 1))', {\n","      'NIR': image.select('B8'),\n","      'RED': image.select('B4'),\n","      'BLUE': image.select('B2')\n","    }).rename('evi')\n","\n","  bsi = image.expression(\n","      '(( X + Y ) - (A + B)) /(( X + Y ) + (A + B)) ', {\n","        'X': image.select('B11'),\n","        'Y': image.select('B4'),\n","        'A': image.select('B8'),\n","        'B': image.select('B2'),\n","    }).rename('bsi')\n","\n","  return image \\\n","    .addBands(ndvi) \\\n","    .addBands(mndwi) \\\n","    .addBands(ndbi) \\\n","    .addBands(evi) \\\n","    .addBands(bsi)\n","\n","\n","# Preparing Sentinel-2 composite\n","\n","def s2CompositePrep(s2, startDate, endDate, gridProjection, geometry):\n","  filteredS2 = s2 \\\n","    .filter(ee.Filter.date(startDate, endDate)) \\\n","    .filter(ee.Filter.bounds(geometry))\n","\n","  # Extract the projection before any processing\n","  s2Projection = ee.Image(filteredS2.first()).select('B4').projection()\n","\n","\n","  # Use Cloud Score+ cloud mask\n","  csPlus = ee.ImageCollection(\n","    'GOOGLE/CLOUD_SCORE_PLUS/V1/S2_HARMONIZED')\n","  csPlusBands = csPlus.first().bandNames()\n","\n","  # We need to add Cloud Score + bands to each Sentinel-2\n","  # image in the collection\n","  # This is done using the linkCollection() function\n","  filteredS2WithCs = filteredS2.linkCollection(\n","    csPlus, csPlusBands)\n","\n","  # Apply all the pre-processing steps\n","  # Order in which the functions are applied is important\n","  s2Processed = filteredS2WithCs \\\n","    .map(maskLowQA) \\\n","    .select('B.*') \\\n","    .map(scaleBands) \\\n","    .map(addIndices)\n","\n","  # Create the S2 composite\n","  s2Composite = s2Processed.median() \\\n","    .setDefaultProjection(gridProjection)\n","\n","  return s2Composite\n","\n","\n","# s2 projection\n","\n","def getS2projection(s2, startDate, endDate, geometry):\n","  filteredS2 = s2 \\\n","    .filter(ee.Filter.date(startDate, endDate)) \\\n","    .filter(ee.Filter.bounds(geometry))\n","\n","  # Extract the projection before any processing\n","  s2Projection = ee.Image(filteredS2.first()).select('B4').projection()\n","\n","  return s2Projection\n","\n","\n","\n","# *********************\n","# CEDA CCI biomass\n","# *********************\n","\n","def cciPrep(biomass_cci, startDate, endDate, gridProjection, geometry):\n","  biomass_cci_filtered = biomass_cci \\\n","    .filter(ee.Filter.date(startDate, endDate)) \\\n","    .filter(ee.Filter.bounds(geometry))\n","\n","  cciProjection = ee.Image(biomass_cci.first()) \\\n","    .select('AGB').projection()\n","\n","  cciMosaic = biomass_cci_filtered.mosaic() \\\n","    .setDefaultProjection(gridProjection)\n","\n","\n","  return cciMosaic\n","\n","\n","# CCI projection\n","\n","def getCCIprojection(biomass_cci, startDate, endDate, geometry):\n","  biomass_cci_filtered = biomass_cci \\\n","    .filter(ee.Filter.date(startDate, endDate)) \\\n","    .filter(ee.Filter.bounds(geometry))\n","\n","  cciProjection = ee.Image(biomass_cci.first()) \\\n","    .select('AGB').projection()\n","\n","  return cciProjection\n","\n","\n","\n","# ************\n","# Export data\n","# ************\n","\n","# Resample to a Grid\n","\n","def stack(array, array_len, gridProjection):\n","\n","  # Create a stacked image\n","  # We assemble a composite with all the bands\n","\n","  stacked = array[0]\n","  for i in range(1, array_len):\n","    stacked = stacked.addBands(array[i])\n","\n","  #  Set the resampling mode\n","  stacked = stacked.resample('bilinear')\n","\n","  # Aggregate pixels with 'mean' statistics\n","  stackedResampled = stacked \\\n","    .reduceResolution(**{\n","      'reducer': ee.Reducer.mean(),\n","      'maxPixels': 1024\n","    }) \\\n","    .reproject(**{\n","    'crs': gridProjection\n","    })\n","\n","  return stackedResampled\n","\n","\n","# Convert the satellite images\n","# and CEDA dataset to a Pandas dataframe\n","\n","def makedfCEDA(stackedCEDA, geometry, gridScale):\n","\n","  training = stackedCEDA.sample(**{\n","      #'numPoints': numSamples,\n","      'region': geometry,\n","      'scale': gridScale,\n","      'tileScale': 16,\n","    })\n","\n","  df = ee.data.computeFeatures({\n","    'expression': training,\n","    'fileFormat': 'PANDAS_DATAFRAME'\n","  })\n","\n","  return df\n","\n","\n","# Convert the satellite images and\n","# CEDA dataset to a CSV file\n","\n","def makeCSVCEDA(stackedCEDA, geometry, gridScale, folder, fileName):\n","\n","  training = stackedCEDA.sample(**{\n","      #'numPoints': numSamples,\n","      'region': geometry,\n","      'scale': gridScale,\n","      'tileScale': 16,\n","    })\n","\n","  task = ee.batch.Export.table.toDrive(**{\n","  'collection': training,\n","  'description': fileName,\n","  'fileFormat': 'CSV',\n","  'folder': folder\n","  })\n","\n","  task.start()\n","\n","\n","# ************\n","# Models\n","# ************\n","\n","# Use models to predict biomass\n","def modelPred(dfC):\n","\n","  models = [\n","    LinearRegression(),\n","   # DecisionTreeRegressor(random_state=0),\n","   # RandomForestRegressor(max_depth=2, random_state=0),\n","    xgb.XGBRegressor()\n","  ]\n","\n","  modelNames = [\n","    'Linear Regression',\n","    #'Decission Tree',\n","    #'Random Forest',\n","    'XGBoost'\n","  ]\n","\n","  nmodels = len(models)\n","\n","  dfC = dfC.dropna()\n","\n","  x = dfC\n","  y = dfC[['AGB']]\n","\n","  x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33)\n","\n","  x_train = x_train.drop(['AGB','SD', 'pSD'], axis=1)\n","  x_test = x_test.drop(['AGB','SD', 'pSD'], axis=1)\n","\n","\n","  y_predAr = []\n","  r2Ar = []\n","  rmseAr = []\n","\n","  for j in range(nmodels):\n","    if modelNames[j] == 'Random Forest':\n","      fitModel = models[j].fit(x_train, y_train.values.ravel())\n","    else:\n","      fitModel = models[j].fit(x_train, y_train)\n","\n","    y_pred = fitModel.predict(x_test)\n","    r2 = r2_score(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred, squared = False)\n","\n","    y_predAr.append(y_pred)\n","    r2Ar.append(r2)\n","    rmseAr.append(rmse)\n","\n","  pred = [y_test, y_predAr, r2Ar, rmseAr, modelNames]\n","\n","  return pred\n","\n","\n","\n","# Use models to predict biomass, weight data according to 1/SD\n","\n","def modelPredErr(dfC):\n","\n","  models = [\n","    LinearRegression(),\n","#    DecisionTreeRegressor(random_state=0),\n","#    RandomForestRegressor(max_depth=2, random_state=0),\n","    xgb.XGBRegressor()\n","  ]\n","\n","  modelNames = [\n","    'Linear Regression',\n"," #   'Decission Tree',\n"," #   'Random Forest',\n","    'XGBoost'\n","  ]\n","\n","  nmodels = len(models)\n","\n","  dfC = dfC.dropna()\n","\n","  x = dfC\n","  y = dfC[['AGB']]\n","\n","  x_train, x_test, y_train, y_test  = train_test_split(x, y, test_size=0.33)\n","\n","  weights = 1/x_train[['SD']]\n","\n","  x_train = x_train.drop(['AGB','SD', 'pSD'], axis=1)\n","  x_test = x_test.drop(['AGB','SD', 'pSD'], axis=1)\n","\n","\n","  y_predAr = []\n","  r2Ar = []\n","  rmseAr = []\n","\n","  for j in range(nmodels):\n","    if modelNames[j] == 'Random Forest':\n","      fitModel = models[j].fit(x_train, y_train.values.ravel(), sample_weight=weights.values.ravel())\n","    else:\n","      fitModel = models[j].fit(x_train, y_train, sample_weight=weights.values.ravel())\n","\n","    y_pred = fitModel.predict(x_test)\n","    r2 = r2_score(y_test, y_pred)\n","    rmse = mean_squared_error(y_test, y_pred, squared = False)\n","\n","    y_predAr.append(y_pred)\n","    r2Ar.append(r2)\n","    rmseAr.append(rmse)\n","\n","  pred = [y_test, y_predAr, scoreAr, modelNames]\n","\n","  return pred\n","\n","# ***********************************\n","# Reading and writing model / EDA\n","# results to a file\n","# ***********************************\n","\n","# EDA on a column\n","def EDAcol(col):\n","\n","  q_ar = [0.05, 0.25, 0.50, 0.75, 0.95]\n","  statNames = ['q05', 'q025', 'q50', 'q75', 'q95', 'rangeL', 'rangeS', 'mean', 'var']\n","\n","  nq = len(q_ar)\n","  statVals = []\n","\n","  for i in range(0, nq):\n","    quant = col.quantile(q_ar[i])\n","    statVals.append(round(quant,4))\n","\n","  rangeL = statVals[nq-1] - statVals[0]\n","  rangeS = statVals[nq-2] - statVals[1]\n","  mean = col.mean()\n","  var = col.var()\n","\n","  statVals.append(round(rangeL,4))\n","  statVals.append(round(rangeS,4))\n","  statVals.append(round(mean,4))\n","  statVals.append(round(var,6))\n","\n","  return statNames, statVals\n","\n","# EDA on a dataframe\n","def EDAdf(df):\n","  colNames = list(df.columns)\n","  ncol = len(colNames)\n","\n","  statValsAll=[]\n","  statNames=[]\n","\n","  for i in range(0, ncol):\n","    statNames, statVals = EDAcol(df[colNames[i]])\n","    statValsAll.append(statVals)\n","\n","  statValsAll = pd.DataFrame(np.array(statValsAll).T, columns=colNames, index = statNames)\n","\n","  return statValsAll\n","\n"," # Write model results to a file\n","def modelResultsToDF(rsq, rmse, modelNames):\n","  names=['rsq', 'rmse']\n","\n","  modelResults=[rsq, rmse]\n","  modelResults = pd.DataFrame(np.array(modelResults).T, columns=names, index = modelNames)\n","  modelResults = modelResults.transpose()\n","\n","  return modelResults\n","\n","# Reading model and EDA results from a file\n","# and storing them in a dataframe\n","def EDAModelFilestoDF(filename):\n","\n","  df = pd.read_csv(filename)\n","  df.rename(columns={df.columns[0]: 'rows'}, inplace=True)\n","  df = df.set_index(df.iloc[:,0])\n","  df = df.drop(['rows'], axis =1)\n","\n","  return df\n","\n","########################### Plottting Functions\n","\n","# clean up dataframe before analysis\n","def cleanDF(filename):\n","  dfC = pd.read_csv(filename)\n","  dfC = dfC.drop(['.geo'], axis=1)\n","  dfC = dfC.drop(['system:index'], axis=1)\n","\n","  # drop missing values\n","  dfC = dfC.dropna()\n","\n","  # add percentage SD column\n","  dfC.loc[dfC['AGB'] == 0, ['AGB']] = 0.001\n","  dfC.loc[dfC['SD'] == 0, ['SD']] = 0.001\n","\n","  dfC['pSD'] = dfC['SD']/dfC['AGB']\n","\n","  # only keep points with percentage error < 1\n","  dfC = dfC[dfC.pSD < 1]\n","\n","  # sampling points for scatter plot to see AGB trend with other variables\n","  if dfC.shape[0] > 1000:\n","    dfCS = dfC.sample(n=1000, random_state=0)\n","  else:\n","    dfCS = dfC\n","\n","  return dfC, dfCS\n","\n","# EDA Plots\n","def EDAplotsAll(placeNameProjectionType, dfC, dfCS):\n","  n_rA = 5 # n_rows\n","  n_cA = 4\n","\n","  props = dict(boxstyle='round, pad=1', facecolor='white')\n","\n","  figTA, axesTA = plt.subplots(n_rA, n_cA) # trends all\n","  figHA, axesHA = plt.subplots(n_rA, n_cA)  # hist all\n","\n","  colName = list(dfC.columns)\n","  df_col_len = len(colName)\n","\n","  for row_num in range(0, n_rA):\n","    for col_num in range(0, n_cA):\n","      df_col = n_cA*row_num + col_num\n","      # scatter plot\n","      loqS = dfCS.iloc[:, df_col].quantile(0.05)\n","      hiqS = dfCS.iloc[:, df_col].quantile(0.95)\n","      axAGBA = axesTA[row_num][col_num]\n","      axAGBA.scatter(dfCS.iloc[:, df_col], dfCS['AGB'], s=2, marker='o')\n","      axAGBA.set_title('AGB vs '+ colName[df_col])\n","      axAGBA.set_xlim([loqS, hiqS])\n","      # histogram\n","      axHistA = axesHA[row_num][col_num]\n","      loq = dfC.iloc[:, df_col].quantile(0.05)\n","      hiq = dfC.iloc[:, df_col].quantile(0.95)\n","      q25 = dfC.iloc[:, df_col].quantile(0.25)\n","      q75 = dfC.iloc[:, df_col].quantile(0.75)\n","      range90 = hiq - loq\n","      range50 = q75 - q25\n","      mean = dfC.iloc[:, df_col].mean()\n","\n","      textstr = 'mean ' + round(mean, 3).astype(str) + '\\n' +'large ' + round(range90, 3).astype(str) + '\\n' + 'small '  + round(range50, 3).astype(str)\n","\n","      col = dfC[dfC.iloc[:, df_col].between(loq, hiq)].iloc[:, df_col]\n","      axHistA.hist(\n","          col,\n","          bins=10, # Number of bins\n","          edgecolor='black', # Color of the border\n","          color='g',\n","          rwidth=0.8\n","        )\n","      axHistA.grid()\n","      axHistA.locator_params(axis='x', nbins=5)\n","      axHistA.set_title(colName[df_col])\n","      hpos=0.7\n","      if colName[df_col] == 'evi' or colName[df_col] == 'ndvi':\n","        hpos=0.05\n","      axHistA.text(hpos, 0.90, textstr, transform=axHistA.transAxes, fontsize=6, verticalalignment='top', bbox=props)\n","\n","      figTA.set_size_inches(15, 10)\n","      figTA.suptitle(placeNameProjectionType, fontsize=12)\n","      figTA.tight_layout(pad=1)\n","\n","      figHA.set_size_inches(15, 10)\n","      figHA.suptitle(placeNameProjectionType, fontsize=12)\n","      figHA.tight_layout(pad=1)\n","\n","  return figTA, figHA\n","\n","def EDAplotsL(placeNameProjectionType, dfC, dfCS):\n","\n","  lesscol = ['AGB', 'B1', 'B8', 'evi', 'ndvi', 'pSD']\n","  props = dict(boxstyle='round , pad=1', facecolor='white')\n","\n","  n_rL = 2 # n_rows less\n","  n_cL = 3\n","  figTL, axesTL = plt.subplots(n_rL, n_cL) # trends less\n","  figHL, axesHL = plt.subplots(n_rL, n_cL) # hist less\n","\n","  for row_num in range(0, n_rL):\n","    for col_num in range(0, n_cL):\n","      df_col = n_cL*row_num + col_num\n","      # scatter plot\n","      loqS = dfCS[lesscol[df_col]].quantile(0.05)\n","      hiqS = dfCS[lesscol[df_col]].quantile(0.95)\n","      axAGBL = axesTL[row_num][col_num]\n","      axAGBL.scatter(dfCS[lesscol[df_col]], dfCS['AGB'], s=3, marker='o')\n","      axAGBL.set_title('AGB vs '+ lesscol[df_col])\n","      axAGBL.set_xlim([loqS, hiqS])\n","      # histogram\n","      axHistL = axesHL[row_num][col_num]\n","      loq = dfC[lesscol[df_col]].quantile(0.05)\n","      hiq = dfC[lesscol[df_col]].quantile(0.95)\n","      q25 = dfC[lesscol[df_col]].quantile(0.25)\n","      q75 = dfC[lesscol[df_col]].quantile(0.75)\n","      range90 = hiq - loq\n","      range50 = q75 - q25\n","      mean = dfC[lesscol[df_col]].mean()\n","\n","      textstr = 'mean ' + round(mean, 3).astype(str) + '\\n\\n' +'large ' + round(range90, 3).astype(str) + '\\n\\n' + 'small '  + round(range50, 3).astype(str)\n","      col = dfC[dfC[lesscol[df_col]].between(loq, hiq)][lesscol[df_col]]\n","      axHistL.hist(\n","          col,\n","          bins=10, # Number of bins\n","          edgecolor='black', # Color of the border\n","          color='g',\n","          rwidth=0.8\n","        )\n","      axHistL.grid()\n","      axHistL.locator_params(axis='x', nbins=5)\n","      axHistL.set_title(lesscol[df_col])\n","      hpos=0.7\n","      if lesscol[df_col] == 'evi' or lesscol[df_col] == 'ndvi':\n","        hpos=0.05\n","      axHistL.text(hpos, 0.95, textstr, transform=axHistL.transAxes, fontsize=10, verticalalignment='top', bbox=props)\n","\n","  figHL.set_size_inches(15, 10)\n","  figHL.suptitle(placeNameProjectionType, fontsize=12)\n","  figHL.tight_layout(pad=1)\n","\n","  figTL.set_size_inches(15, 10)\n","  figTL.suptitle(placeNameProjectionType, fontsize=12)\n","  figTL.tight_layout(pad=1)\n","\n","  return figTL, figHL\n","\n","# Correlation plots\n","def corrPlots(placeNameProjectionType, dfC):\n","  lesscol = ['AGB', 'B1', 'B8', 'evi', 'ndvi', 'pSD']\n","\n","  figCorr = plt.figure(figsize=(16, 10))\n","  heatmap = sns.heatmap(dfC.corr(), vmin=-1, vmax=1, annot=True, cmap=\"viridis_r\")\n","  heatmap.set_title(placeNameProjectionType, fontdict={'fontsize':18}, pad=12)\n","\n","  figCorrL = plt.figure(figsize=(16, 10))\n","  heatmapL = sns.heatmap(dfC[lesscol].corr(), vmin=-1, vmax=1, annot=True, cmap=\"viridis_r\")\n","  heatmapL.set_title(placeNameProjectionType, fontdict={'fontsize':18}, pad=12)\n","\n","  return figCorr, figCorrL\n","\n","# Plot model results\n","def modelPlots(placeNameProjectionType, pred):\n","  y_test = pred[0]\n","  y_predAr = pred[1]\n","  r2Ar = pred[2]\n","  rmseAr = pred[3]\n","  modelNames = pred[4]\n","\n","  # Plots of model results\n","  props = dict(boxstyle='round', facecolor='white')\n","\n","  n_cols = 2\n","\n","  figModels, axesModels = plt.subplots(1, n_cols)\n","\n","  for iModel in range(0, n_cols):\n","    axModels = axesModels[iModel]\n","    axModels.scatter(y_test, y_predAr[iModel], s=2, marker='o')\n","    axModels.set_title(modelNames[iModel]) #+ ' Rsq ' + round(r2Ar[iModel], 2).astype(str) + ' RMSE ' + round(rmseAr[iModel], 2).astype(str))\n","    textstr = 'Rsq ' + round(r2Ar[iModel], 3).astype(str) + '\\n\\n' +'RMSE ' + round(rmseAr[iModel], 3).astype(str)\n","    axModels.text(0.05, 0.95, textstr, transform=axModels.transAxes, fontsize=12, verticalalignment='top')\n","\n","  figModels.set_size_inches(16, 8)\n","  figModels.suptitle('y_pred vs y_test ' + placeNameProjectionType, fontsize=12)\n","  figModels.tight_layout(pad=2)\n","\n","  return figModels"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"r2ymBvR_P2hH","executionInfo":{"status":"ok","timestamp":1711622910198,"user_tz":-330,"elapsed":395,"user":{"displayName":"Abha Rajan","userId":"00306822163379284153"}},"outputId":"c3d472d2-9b7f-4495-e25e-87752b211dcb"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","            <style>\n","                .geemap-dark {\n","                    --jp-widgets-color: white;\n","                    --jp-widgets-label-color: white;\n","                    --jp-ui-font-color1: white;\n","                    --jp-layout-color2: #454545;\n","                    background-color: #383838;\n","                }\n","\n","                .geemap-dark .jupyter-button {\n","                    --jp-layout-color3: #383838;\n","                }\n","\n","                .geemap-colab {\n","                    background-color: var(--colab-primary-surface-color, white);\n","                }\n","\n","                .geemap-colab .jupyter-button {\n","                    --jp-layout-color3: var(--colab-primary-surface-color, white);\n","                }\n","            </style>\n","            "]},"metadata":{}}]}]}